{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "84597efe",
      "metadata": {
        "id": "84597efe"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitesei/EnsembleLab/blob/main/EnsembleLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e4c6f7d",
      "metadata": {
        "id": "3e4c6f7d"
      },
      "source": [
        "## **Preliminary information:**\n",
        "\n",
        "This Colab notebook enables running molecular dynamics (MD) simulations of intrinsically disordered proteins (IDPs) and protein regions (IDRs) and to study their conformational ensembles [1].\n",
        "\n",
        "MD simulations employ the coarse-grained force field CALVADOS 2 [2], where each residue is mapped onto a single bead and modeled with a stickiness parameter and electrostatics.\n",
        "\n",
        "Simulations are run using openMM [3] and only require that the user (i) provides the sequence of an IDP, (ii) sets environmental conditions, and the charge states of His residues and terminal amino and carboxyl groups.\n",
        "\n",
        "Coarse-grained trajectories are converted to all-atom trajectories using the _powerful chain restoration algorithm_ (PULCHRA) [4].\n",
        "\n",
        "Small angle X-ray scattering curves are calculated using _polynomial expansions of protein structures and interactions_ (Pepsi)-SAXS [5].\n",
        "\n",
        "Bayesian/Maximum Entropy Reweighting is performed using the BME Python library [6].\n",
        "\n",
        "### Usage\n",
        "\n",
        "MD simulations run on GPU. To enable GPU select `Runtime` from the menu, then `Change runtime type` and select `GPU`.\n",
        "\n",
        "__Note:__ Cells for preliminary operations should be executed one by one to prevent crashes. This notebook uses condacolab, whose installation will cause a kernel restart. Because of this, a crash will happen during preliminary operations if you execute all cells at once.\n",
        "\n",
        "### References\n",
        "\n",
        "If you use this notebook, you may consider citing the following papers:\n",
        "\n",
        "1. G. Tesei, A. I. Trolle, N. Jonsson, J. Betz, F. E. Knudsen, F. Pesce, K. E. Johansson, K. Lindorff-Larsen __Conformational ensembles of the human intrinsically disordered proteome__ _Nature_ 2024 626:897–904 2023.05.08.539815 DOI: https://doi.org/10.1038/s41586-023-07004-5\n",
        "\n",
        "2. G. Tesei and K. Lindorff-Larsen __Improved predictions of phase behaviour of intrinsically disordered proteins by tuning the interaction range [version 2; peer review: 2 approved]__ _Open Research Europe_ 2023 2(94) DOI: https://doi.org/10.12688/openreseurope.14967.2\n",
        "\n",
        "3. P. Eastman, J. Swails, J. D. Chodera et al. __OpenMM 7: Rapid development of high performance algorithms for molecular dynamics__ _PLoS Computational Biology_ 2017 13(7):e1005659 DOI: https://doi.org/10.1371/journal.pcbi.1005659\n",
        "\n",
        "4. P. Rotkiewicz and J. Skolnick __Fast procedure for reconstruction of full-atom protein models from reduced representations__ _J. Comput. Chem._ 2008 29:1460–1465 DOI: https://doi.org/10.1002/jcc.20906\n",
        "\n",
        "5. S. Grudinin, M. Garkavenko, and A. Kazennov __Pepsi-SAXS: an adaptive method for rapid and accurate computation of small-angle x-ray scattering profiles__ _Acta Crystallogr. D Struct. Biol_ 2017 73:449–464 DOI: https://doi.org/10.1107/S2059798317005745\n",
        "\n",
        "6. S. Bottaro, T. Bengtsen, and K. Lindorff-Larsen __Integrating Molecular Simulation and Experimental Data: A Bayesian/Maximum Entropy Reweighting Approach__ _Methods Mol. Biol._ 2020 2112:219–240 DOI: https://doi.org/10.1007/978-1-0716-0270-6_15\n",
        "\n",
        "---\n",
        "\n",
        "Authors: Francesco Pesce and Giulio Tesei"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ccfc48",
      "metadata": {
        "cellView": "form",
        "id": "e1ccfc48"
      },
      "outputs": [],
      "source": [
        "#@title <b>Preliminary operations</b>: setting the environment (i)\n",
        "#@markdown Run the three “Preliminary operations” cells one by one, waiting for the execution of each cell to be complete (a green check mark will appear) before running the next. When the execution of “Preliminary operations: setting the environment (i)” is complete, the session will restart and Colab will report a message related to the session crashing. That is required for all packages to work properly.\n",
        "import subprocess\n",
        "subprocess.run('pip install -q condacolab'.split())\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836d1c1b",
      "metadata": {
        "cellView": "form",
        "id": "836d1c1b"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#E3B505'>0 - Input protein sequence</font></b>\n",
        "#@markdown At https://github.com/gitesei/EnsembleLab/tree/main/example_data you can find sequences and SAXS data for 11 IDPs. Choose the IDP you want to work with and download its sequence (“.fasta” file) and SAXS data (“.dat” file). Otherwise, you can use your own data. Temperature, ionic strength and pH should be set so as to reproduce the experimental conditions used for the SAXS experiment (see https://github.com/gitesei/EnsembleLab/blob/main/example_data/exp_conditions.csv and DOI: 10.1016/j.bpj.2022.12.013)\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    os.rmdir('sample_data')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "#@markdown Name the IDP that you want to simulate:\n",
        "NAME = \"Hst5\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Insert here the sequence of the IDP that you want to simulate:\n",
        "SEQUENCE = \"DSHAKRHHGYKRKFHEKHHSHRGY\" #@param {type:\"string\"}\n",
        "if \" \" in SEQUENCE:\n",
        "    SEQUENCE = ''.join(SEQUENCE.split())\n",
        "    print('Blank character(s) found in the provided sequence. Sequence has been corrected, but check for integrity:')\n",
        "    print(SEQUENCE)\n",
        "    print('\\n')\n",
        "\n",
        "#@markdown Simulation settings:\n",
        "temperature = 293 #@param {type:\"number\"}\n",
        "ionic_strength = 0.166 #@param {type:\"number\"}\n",
        "#@markdown <i>*Units: Temperature [K], Ionic_strength [M]<i>\n",
        "\n",
        "#@markdown Set the charge state of histidine as $\\frac{1}{1+10^{pH-pKa}}$:\n",
        "charged_histidine = True #@param {type:\"boolean\"}\n",
        "\n",
        "if charged_histidine == True:\n",
        "    print('Define pH and pKa to set the charge of Histidines according to the Henderson-Hasselbalch equation.')\n",
        "    pH = input('Enter pH value: ')\n",
        "    pH = float(pH)\n",
        "    pKa = input('Enter pKa value: ')\n",
        "    pKa = float(pKa)\n",
        "    Hc = 1/(1+10**(pH-pKa))\n",
        "if charged_histidine == False:\n",
        "    Hc = 0\n",
        "\n",
        "np.savetxt('env_settings.txt', np.array([temperature, ionic_strength, Hc]).T, header='temperature ionic_strength, His_charge, N_term_charge, C_term_charge')\n",
        "\n",
        "#@markdown Are experimental data available for this IDP? If so, a prompt will appear to allow you to upload a file containing the SAXS data.\n",
        "EXPERIMENT = \"SAXS\" #@param [\"None\", \"SAXS\", \"Rh (to be implemented)\"]\n",
        "\n",
        "if EXPERIMENT == \"SAXS\":\n",
        "    print('SAXS data must be in a file containing 3 columns, which are q, I and sigma. Commented lines (#) are allowed.')\n",
        "    print('Please upload to session storage a properly formatted file containing SAXS data.')\n",
        "    tmp = files.upload()\n",
        "    saxs_file = list(tmp.keys())[0]\n",
        "\n",
        "    #check data\n",
        "    try:\n",
        "        np.loadtxt(saxs_file)\n",
        "    except:\n",
        "        print(\"Unable to read file. Make sure the file only contains 3 columns (q,I,sigma) and #commented lines\")\n",
        "    assert np.shape(np.loadtxt(saxs_file))[1] == 3, \"Expected file with 3 columns (q,I,sigma)\"\n",
        "\n",
        "    exp_saxs = np.loadtxt(saxs_file)\n",
        "    if exp_saxs[...,0][-1] <  1:\n",
        "        print('q is in Å units. Converting to nm.')\n",
        "        exp_saxs[...,0] = exp_saxs[...,0]*10\n",
        "        np.savetxt(saxs_file, exp_saxs)\n",
        "\n",
        "    if (exp_saxs[...,0] >= 5).sum() > 0:\n",
        "        print('Found {} q-values above 5 nm^(-1). SAXS calculations are not reliable in that region of the spectrum. Those datapoints will be remove'.format((exp_saxs[...,0] >= 5).sum()))\n",
        "        exp_saxs = exp_saxs[(exp_saxs[...,0] < 5)]\n",
        "        np.savetxt(saxs_file, exp_saxs)\n",
        "\n",
        "    shutil.move(saxs_file, 'saxs_input.dat')\n",
        "\n",
        "# Need to store metadata prior to condacolab restarting the kernel\n",
        "f = open('seq.fasta','w')\n",
        "f.write('>{:s}\\n{:s}'.format(NAME,SEQUENCE))\n",
        "f.close()\n",
        "try:\n",
        "    os.mkdir('{:s}'.format(EXPERIMENT))\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a29e3190",
      "metadata": {
        "cellView": "form",
        "id": "a29e3190"
      },
      "outputs": [],
      "source": [
        "#@title <b>Preliminary operations</b>: acquiring software (ii)\n",
        "%%bash\n",
        "\n",
        "rm -r sample_data\n",
        "\n",
        "wget https://github.com/fpesceKU/EnsembleLab/raw/main/utils/pulchra &> /dev/null\n",
        "chmod +x pulchra\n",
        "\n",
        "wget https://files.inria.fr/NanoDFiles/Website/Software/Pepsi-SAXS/Linux/3.0/Pepsi-SAXS-Linux.zip &> /dev/null\n",
        "unzip Pepsi-SAXS-Linux.zip &> /dev/null\n",
        "rm Pepsi-SAXS-Linux.zip\n",
        "\n",
        "wget https://raw.githubusercontent.com/fpesceKU/BLOCKING/main/block_tools.py &> /dev/null\n",
        "wget https://raw.githubusercontent.com/fpesceKU/BLOCKING/main/main.py &> /dev/null\n",
        "\n",
        "wget https://raw.githubusercontent.com/KULL-Centre/BME/main/BME_tools.py &> /dev/null\n",
        "wget https://raw.githubusercontent.com/KULL-Centre/BME/main/BME.py &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192677f7",
      "metadata": {
        "cellView": "form",
        "id": "192677f7"
      },
      "outputs": [],
      "source": [
        "#@title <b>Preliminary operations</b>: setting the environment (iii)\n",
        "import subprocess\n",
        "subprocess.run( 'pip install -q condacolab'.split() )\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b090e2a4",
      "metadata": {
        "cellView": "form",
        "id": "b090e2a4"
      },
      "outputs": [],
      "source": [
        "#@title <b>Preliminary operations</b>: setting the environment (iv)\n",
        "import subprocess\n",
        "print('Installing libraries...')\n",
        "_ = subprocess.run('conda install matplotlib mdtraj openmm=7.7.0 cudatoolkit=11.8 -c conda-forge --yes'.split())\n",
        "subprocess.run('pip install wget statsmodels localcider==0.1.18 kneed==0.5.0'.split())\n",
        "subprocess.run('pip uninstall scikit-learn -y'.split())\n",
        "subprocess.run('pip install scikit-learn==1.0.2'.split())\n",
        "import wget\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as scs\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import mdtraj as md\n",
        "from simtk import openmm, unit\n",
        "from simtk.openmm import app\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import BME as BME\n",
        "from kneed import KneeLocator\n",
        "from google.colab import files\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')\n",
        "from ipywidgets import interactive\n",
        "import ipywidgets as widgets\n",
        "import itertools\n",
        "from sklearn.covariance import LedoitWolf\n",
        "from scipy import constants\n",
        "from numpy import linalg\n",
        "from joblib import load\n",
        "from localcider.sequenceParameters import SequenceParameters\n",
        "from main import BlockAnalysis\n",
        "from simtk import openmm, unit\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')\n",
        "from ipywidgets import interactive\n",
        "import ipywidgets as widgets\n",
        "from statsmodels.stats.weightstats import DescrStatsW\n",
        "from IPython.display import HTML, display\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9966036f",
      "metadata": {
        "cellView": "form",
        "id": "9966036f"
      },
      "outputs": [],
      "source": [
        "#@title <b>Preliminary operations</b>: downloading PULCHRA, Pepsi-SAXS, BLOCKING, and BME (v)\n",
        "%%bash\n",
        "\n",
        "rm -r sample_data\n",
        "\n",
        "wget https://github.com/fpesceKU/EnsembleLab/raw/main/utils/pulchra &> /dev/null\n",
        "chmod +x pulchra\n",
        "\n",
        "wget https://files.inria.fr/NanoDFiles/Website/Software/Pepsi-SAXS/Linux/3.0/Pepsi-SAXS-Linux.zip &> /dev/null\n",
        "unzip Pepsi-SAXS-Linux.zip &> /dev/null\n",
        "rm Pepsi-SAXS-Linux.zip\n",
        "\n",
        "wget https://raw.githubusercontent.com/fpesceKU/BLOCKING/main/block_tools.py &> /dev/null\n",
        "wget https://raw.githubusercontent.com/fpesceKU/BLOCKING/main/main.py &> /dev/null\n",
        "\n",
        "wget https://raw.githubusercontent.com/KULL-Centre/BME/main/BME_tools.py &> /dev/null\n",
        "wget https://raw.githubusercontent.com/KULL-Centre/BME/main/BME.py &> /dev/null\n",
        "\n",
        "wget https://raw.githubusercontent.com/ehb54/GenApp-BayesApp/main/bin/source/bift.f &> /dev/null\n",
        "gfortran bift.f -march=native -O2 -o bift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b896948",
      "metadata": {
        "cellView": "form",
        "id": "0b896948"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#FA003F'>1.1 MD Toolbox</font></b>\n",
        "try:\n",
        "    os.remove('residues.csv'.format(NAME))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "url = 'https://github.com/KULL-Centre/_2023_Tesei_IDRome/blob/main'\n",
        "if os.path.exists('residues.csv') == False:\n",
        "    wget.download(url+'/md_simulations/data/residues.csv?raw=true')\n",
        "residues = pd.read_csv('residues.csv')\n",
        "residues = residues.set_index('one')\n",
        "#Breaking CALVADOS\n",
        "Break_CALVADOS = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown By checking the \"Break_CALVADOS\" box, you will add random noise up to 40% in CALVADOS' lambda values (the amino-acid stickiness parameters). As a consequence, the resulting simulations will not be trustworthy. This function has been added for teaching purposes, so that the effect of reweighting could be appreciated more when using a force field that does not reproduce experimental data accurately.\n",
        "if Break_CALVADOS == True:\n",
        "    residues['lambdas'] = residues.lambdas.values*(np.random.rand(residues.index.size)*0.5+0.6)\n",
        "    print (\"WARNING: CALVADOS' lambdas have been randomly modified. This function is only for teaching purpose.\")\n",
        "\n",
        "if os.path.exists('svr_model_nu.joblib') == False:\n",
        "    wget.download(url+'/svr_models/svr_model_nu.joblib?raw=true')\n",
        "if os.path.exists('svr_model_SPR.joblib') == False:\n",
        "    wget.download(url+'/svr_models/svr_model_SPR.joblib?raw=true')\n",
        "\n",
        "\n",
        "def genParamsLJ(df,seq):\n",
        "    fasta = seq.copy()\n",
        "    r = df.copy()\n",
        "    r.loc['X'] = r.loc[fasta[0]]\n",
        "    r.loc['X','MW'] += 2\n",
        "    fasta[0] = 'X'\n",
        "    r.loc['Z'] = r.loc[fasta[-1]]\n",
        "    r.loc['Z','MW'] += 16\n",
        "    fasta[-1] = 'Z'\n",
        "    types = list(np.unique(fasta))\n",
        "    lj_eps = 0.2*4.184\n",
        "    lj_sigma = pd.DataFrame((r.sigmas.values+r.sigmas.values.reshape(-1,1))/2,\n",
        "                            index=r.sigmas.index,columns=r.sigmas.index)\n",
        "    lj_lambda = pd.DataFrame((r.lambdas.values+r.lambdas.values.reshape(-1,1))/2,\n",
        "                             index=r.lambdas.index,columns=r.lambdas.index)\n",
        "    return lj_eps, lj_sigma, lj_lambda, fasta, types\n",
        "\n",
        "def genParamsDH(df,seq,temp,ionic,Hc):\n",
        "    kT = 8.3145*temp*1e-3\n",
        "    fasta = seq.copy()\n",
        "    r = df.copy()\n",
        "    # Set the charge on HIS based on the pH of the protein solution\n",
        "    r.q = r.q.astype(float)\n",
        "    r.loc['H','q'] = Hc\n",
        "    r.loc['X'] = r.loc[fasta[0]]\n",
        "    r.loc['X','q'] = r.loc[seq[0],'q'] + 1.\n",
        "    fasta[0] = 'X'\n",
        "    r.loc['Z'] = r.loc[fasta[-1]]\n",
        "    r.loc['Z','q'] = r.loc[seq[-1],'q'] - 1.\n",
        "    fasta[-1] = 'Z'\n",
        "    # Calculate the prefactor for the Yukawa potential\n",
        "    fepsw = lambda T : 5321/T+233.76-0.9297*T+0.1417*1e-2*T*T-0.8292*1e-6*T**3\n",
        "    epsw = fepsw(temp)\n",
        "    lB = 1.6021766**2/(4*np.pi*8.854188*epsw)*6.022*1000/kT\n",
        "    yukawa_eps = [r.loc[a].q*np.sqrt(lB*kT) for a in fasta]\n",
        "    # Calculate the inverse of the Debye length\n",
        "    yukawa_kappa = np.sqrt(8*np.pi*lB*ionic*6.022/10)\n",
        "    return yukawa_eps, yukawa_kappa\n",
        "\n",
        "def genXTC(name, eqsteps=10):\n",
        "    \"\"\"\n",
        "    Generates coordinate and trajectory\n",
        "    in convenient formats\n",
        "    \"\"\"\n",
        "    traj = md.load(\"{:s}/pretraj.dcd\".format(name), top=\"{:s}/top.pdb\".format(name))\n",
        "    traj.center_coordinates()\n",
        "    traj.xyz += traj.unitcell_lengths[0,0]/2\n",
        "    cgtop = md.Topology()\n",
        "    cgchain = cgtop.add_chain()\n",
        "    for atom in traj.top.atoms:\n",
        "        cgres = cgtop.add_residue(atom.name, cgchain)\n",
        "        cgtop.add_atom('CA', element=md.element.carbon, residue=cgres)\n",
        "    traj = md.Trajectory(traj.xyz, cgtop, traj.time, traj.unitcell_lengths, traj.unitcell_angles)\n",
        "    traj[int(eqsteps):].save_xtc(\"{:s}/traj.xtc\".format(name))\n",
        "    traj[int(eqsteps)].save_pdb(\"{:s}/top.pdb\".format(name))\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "def simulate(residues,name,seq,temp,ionic,Hc,nsteps,stride=1e3,eqsteps=1000):\n",
        "    os.mkdir(name)\n",
        "\n",
        "    lj_eps, _, _, fasta, types= genParamsLJ(residues,seq)\n",
        "    yukawa_eps, yukawa_kappa = genParamsDH(residues,seq,temp,ionic,Hc)\n",
        "\n",
        "    N = len(fasta)\n",
        "    L = (N-1)*0.38+4\n",
        "\n",
        "    system = openmm.System()\n",
        "\n",
        "    # set box vectors\n",
        "    a = unit.Quantity(np.zeros([3]), unit.nanometers)\n",
        "    a[0] = L * unit.nanometers\n",
        "    b = unit.Quantity(np.zeros([3]), unit.nanometers)\n",
        "    b[1] = L * unit.nanometers\n",
        "    c = unit.Quantity(np.zeros([3]), unit.nanometers)\n",
        "    c[2] = L * unit.nanometers\n",
        "    system.setDefaultPeriodicBoxVectors(a, b, c)\n",
        "\n",
        "    top = md.Topology()\n",
        "    pos = []\n",
        "    chain = top.add_chain()\n",
        "    pos.append([[0,0,L/2+(i-N/2.)*.38] for i in range(N)])\n",
        "    for resname in fasta:\n",
        "        residue = top.add_residue(resname, chain)\n",
        "        top.add_atom(resname, element=md.element.carbon, residue=residue)\n",
        "    for i in range(chain.n_atoms-1):\n",
        "        top.add_bond(chain.atom(i),chain.atom(i+1))\n",
        "    md.Trajectory(np.array(pos).reshape(N,3), top, 0, [L,L,L], [90,90,90]).save_pdb('{:s}/top.pdb'.format(name))\n",
        "\n",
        "    pdb = app.pdbfile.PDBFile('{:s}/top.pdb'.format(name))\n",
        "\n",
        "    system.addParticle((residues.loc[seq[0]].MW+2)*unit.amu)\n",
        "    for a in seq[1:-1]:\n",
        "        system.addParticle(residues.loc[a].MW*unit.amu)\n",
        "    system.addParticle((residues.loc[seq[-1]].MW+16)*unit.amu)\n",
        "\n",
        "    hb = openmm.openmm.HarmonicBondForce()\n",
        "    energy_expression = f'{lj_eps}*select(step(r-2^(1/6)*s),4*l*((s/r)^12-(s/r)^6-shift),4*((s/r)^12-(s/r)^6-l*shift)+(1-l))'\n",
        "    ah = openmm.openmm.CustomNonbondedForce(energy_expression+f'; s=0.5*(s1+s2); l=0.5*(l1+l2); shift=(0.5*(s1+s2)/2.0)^12-(0.5*(s1+s2)/2.0)^6')\n",
        "    ah.addPerParticleParameter('s')\n",
        "    ah.addPerParticleParameter('l')\n",
        "    shift = np.exp(-yukawa_kappa*4.0)/4.0\n",
        "    yu = openmm.openmm.CustomNonbondedForce(f'q*(exp(-{yukawa_kappa}*r)/r-{shift}); q=q1*q2')\n",
        "    yu.addPerParticleParameter('q')\n",
        "\n",
        "    for a,e in zip(seq,yukawa_eps):\n",
        "        yu.addParticle([e*unit.nanometer*unit.kilojoules_per_mole])\n",
        "        ah.addParticle([residues.loc[a].sigmas*unit.nanometer, residues.loc[a].lambdas*unit.dimensionless])\n",
        "\n",
        "    for i in range(N-1):\n",
        "        hb.addBond(i, i+1, 0.38*unit.nanometer, 8033*unit.kilojoules_per_mole/(unit.nanometer**2))\n",
        "        yu.addExclusion(i, i+1)\n",
        "        ah.addExclusion(i, i+1)\n",
        "\n",
        "    yu.setForceGroup(0)\n",
        "    ah.setForceGroup(1)\n",
        "    yu.setNonbondedMethod(openmm.openmm.CustomNonbondedForce.CutoffPeriodic)\n",
        "    ah.setNonbondedMethod(openmm.openmm.CustomNonbondedForce.CutoffPeriodic)\n",
        "    hb.setUsesPeriodicBoundaryConditions(True)\n",
        "    yu.setCutoffDistance(4*unit.nanometer)\n",
        "    ah.setCutoffDistance(2*unit.nanometer)\n",
        "\n",
        "    system.addForce(hb)\n",
        "    system.addForce(yu)\n",
        "    system.addForce(ah)\n",
        "\n",
        "    integrator = openmm.openmm.LangevinIntegrator(temp*unit.kelvin,0.01/unit.picosecond,0.010*unit.picosecond) #10 fs timestep\n",
        "\n",
        "    try:\n",
        "        platform = openmm.Platform.getPlatformByName('CUDA')\n",
        "        simulation = app.simulation.Simulation(pdb.topology, system, integrator, platform, dict(CudaPrecision='mixed'))\n",
        "    except openmm.OpenMMException:\n",
        "        platform = openmm.Platform.getPlatformByName('CPU')\n",
        "        simulation = app.simulation.Simulation(pdb.topology, system, integrator, platform)\n",
        "\n",
        "    check_point = '{:s}/restart.chk'.format(name)\n",
        "\n",
        "    if os.path.isfile(check_point):\n",
        "        print('Reading check point file')\n",
        "        simulation.loadCheckpoint(check_point)\n",
        "        simulation.reporters.append(app.dcdreporter.DCDReporter('{:s}/pretraj.dcd'.format(name),int(stride),append=True))\n",
        "    else:\n",
        "        simulation.context.setPositions(pdb.positions)\n",
        "        simulation.minimizeEnergy()\n",
        "        simulation.reporters.append(app.dcdreporter.DCDReporter('{:s}/pretraj.dcd'.format(name),int(stride)))\n",
        "\n",
        "    simulation.reporters.append(app.statedatareporter.StateDataReporter('{:s}/traj.log'.format(name),int(stride),\n",
        "             potentialEnergy=True,temperature=True,step=True,speed=True,elapsedTime=True,separator='\\t'))\n",
        "\n",
        "    out = display(progress(0, 100), display_id=True)\n",
        "    nbatch = int(nsteps / 1000)\n",
        "    for i in range(1000):\n",
        "        time.sleep(0.02)\n",
        "        simulation.step(nbatch)\n",
        "        simulation.saveCheckpoint(check_point)\n",
        "        out.update(progress(i/10, 100))\n",
        "\n",
        "    genXTC(name,eqsteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f8291c",
      "metadata": {
        "cellView": "form",
        "id": "03f8291c"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#A79AB2'>Sequence analysis Toolbox</font></b>\n",
        "def calc_seq_prop(seq,residues,Hc):\n",
        "    \"\"\"df: DataFrame to be populated with sequence properties\n",
        "    r: DataFrame of aa-specific parameters\"\"\"\n",
        "    model_nu = load('svr_model_nu.joblib')\n",
        "    model_spr = load('svr_model_SPR.joblib')\n",
        "\n",
        "    seq = list(seq).copy()\n",
        "    fasta_kappa = np.array(seq.copy())\n",
        "    N = len(seq)\n",
        "    r = residues.copy()\n",
        "\n",
        "    # calculate properties that do not depend on charges\n",
        "    fK = sum([seq.count(a) for a in ['K']])/N\n",
        "    fR = sum([seq.count(a) for a in ['R']])/N\n",
        "    fE = sum([seq.count(a) for a in ['E']])/N\n",
        "    fD = sum([seq.count(a) for a in ['D']])/N\n",
        "    faro = sum([seq.count(a) for a in ['W','Y','F']])/N\n",
        "    mean_lambda = np.mean(r.loc[seq].lambdas)\n",
        "\n",
        "    pairs = np.array(list(itertools.combinations(seq,2)))\n",
        "    pairs_indices = np.array(list(itertools.combinations(range(N),2)))\n",
        "    # calculate sequence separations\n",
        "    ij_dist = np.diff(pairs_indices,axis=1).flatten().astype(float)\n",
        "    # calculate lambda sums\n",
        "    ll = r.lambdas.loc[pairs[:,0]].values+r.lambdas.loc[pairs[:,1]].values\n",
        "    # calculate SHD\n",
        "    beta = -1\n",
        "    shd = np.sum(ll*np.power(np.abs(ij_dist),beta))/N\n",
        "\n",
        "    # fix charges\n",
        "    r.loc['X'] = r.loc[seq[0]]\n",
        "    r.loc['X','q'] = r.loc[seq[0],'q'] + 1.\n",
        "    seq[0] = 'X'\n",
        "    if r.loc['X','q'] > 0:\n",
        "        fasta_kappa[0] = 'K'\n",
        "    else:\n",
        "        fasta_kappa[0] = 'A'\n",
        "    r.loc['Z'] = r.loc[seq[-1]]\n",
        "    r.loc['Z','q'] = r.loc[seq[-1],'q'] - 1.\n",
        "    seq[-1] = 'Z'\n",
        "    if r.loc['Z','q'] < 0:\n",
        "        fasta_kappa[-1] = 'D'\n",
        "    else:\n",
        "        fasta_kappa[-1] = 'A'\n",
        "    if Hc < 0.5:\n",
        "        r.loc['H', 'q'] = 0\n",
        "        fasta_kappa[np.where(np.array(seq) == 'H')[0]] = 'A'\n",
        "    elif Hc >= 0.5:\n",
        "        r.loc['H', 'q'] = 1\n",
        "        fasta_kappa[np.where(np.array(seq) == 'H')[0]] = 'K'\n",
        "\n",
        "    # calculate properties that depend on charges\n",
        "    pairs = np.array(list(itertools.combinations(seq,2)))\n",
        "    # calculate charge products\n",
        "    qq = r.q.loc[pairs[:,0]].values*r.q.loc[pairs[:,1]].values\n",
        "    # calculate SCD\n",
        "    scd = np.sum(qq*np.sqrt(ij_dist))/N\n",
        "    SeqOb = SequenceParameters(''.join(fasta_kappa))\n",
        "    kappa = SeqOb.get_kappa()\n",
        "    fcr = r.q.loc[seq].abs().mean()\n",
        "    ncpr = r.q.loc[seq].mean()\n",
        "\n",
        "    nu_svr = model_nu.predict([[scd,shd,kappa,fcr,mean_lambda]])[0]\n",
        "    spr_svr = model_spr.predict([[scd,shd,mean_lambda]])[0]\n",
        "\n",
        "    return np.around([fK, fR, fE, fD, faro, mean_lambda, shd, scd,\n",
        "                      kappa, fcr, ncpr, nu_svr, spr_svr],3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4a3243",
      "metadata": {
        "cellView": "form",
        "id": "3c4a3243"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#A79AB2'>Simulation analysis Toolbox</font></b>\n",
        "def autoblock(cv, multi=1, plot=False):\n",
        "    block = BlockAnalysis(cv, multi=multi)\n",
        "    block.SEM()\n",
        "\n",
        "    if plot == True:\n",
        "        plt.errorbar(block.stat[...,0], block.stat[...,1], block.stat[...,2], fmt='', color='k', ecolor='0.5')\n",
        "        plt.scatter(block.bs, block.sem,zorder=10,c='tab:red')\n",
        "        plt.xlabel('Block size')\n",
        "        plt.ylabel('SEM')\n",
        "        plt.show()\n",
        "\n",
        "    return block.av, block.sem, block.bs\n",
        "\n",
        "def fix_topology_pulchra(t,seq):\n",
        "    cgtop = md.Topology()\n",
        "    cgchain = cgtop.add_chain()\n",
        "    for res in seq:\n",
        "        cgres = cgtop.add_residue(res, cgchain)\n",
        "        cgtop.add_atom('CA', element=md.element.carbon, residue=cgres)\n",
        "    traj = md.Trajectory(t.xyz, cgtop, t.time, t.unitcell_lengths, t.unitcell_angles)\n",
        "    traj = traj.superpose(traj, frame=0)\n",
        "    return traj\n",
        "\n",
        "def backmapping(name, traj):\n",
        "    for i in range(traj.n_frames):\n",
        "        traj[i].save_pdb('frame.pdb')\n",
        "        subprocess.run(['./pulchra', 'frame.pdb'])\n",
        "        if i == 0:\n",
        "            traj_AA = md.load_pdb('frame.rebuilt.pdb')\n",
        "        else:\n",
        "            traj_AA += md.load_pdb('frame.rebuilt.pdb')\n",
        "    top = md.Topology()\n",
        "    chain = top.add_chain()\n",
        "    for residue in traj_AA.top.residues:\n",
        "        res = top.add_residue(residue.name, chain, resSeq=residue.index+1)\n",
        "        for atom in residue.atoms:\n",
        "            top.add_atom(atom.name, element=atom.element, residue=res)\n",
        "    traj_AA = md.Trajectory(traj_AA.xyz, top, traj.time, traj.unitcell_lengths, traj.unitcell_angles)\n",
        "    traj_AA[0].save_pdb(f'{name:s}/top_AA.pdb')\n",
        "    traj_AA.save_dcd(f'{name:s}/traj_AA.dcd')\n",
        "    return traj_AA\n",
        "\n",
        "def plot_dist(ax,x,p,av,color='k'):\n",
        "    ax.plot(x,p,c=color)\n",
        "    ax.axvline(av,color=color)\n",
        "    ax.set_xlim(np.min(x), np.max(x))\n",
        "    ax.set_ylim(0,np.max(p)*1.1)\n",
        "\n",
        "def plot_rew_dist(ax,x,p,av):\n",
        "    ax.plot(x,p,c='tab:red')\n",
        "    ax.axvline(av,0,100, color='tab:red')\n",
        "    ax.set_xlim(np.min(x), np.max(x))\n",
        "    ax.set_ylim(0,np.max(p)*1.1)\n",
        "\n",
        "def error_ratio(v1,v2,e1,e2):\n",
        "    ratio = v1/v2\n",
        "    return ratio*np.sqrt((e1/v1)**2+(e2/v2)**2)\n",
        "\n",
        "def calc_shape_and_entropy(t,forces,residues,seq,temp):\n",
        "    fasta = list(seq)\n",
        "    masses = residues.loc[fasta,'MW'].values[np.newaxis,:,np.newaxis]\n",
        "\n",
        "    # calculate conformational entropy per residue (DOI: 10.1021/ct500684w)\n",
        "    prefactor = constants.Boltzmann*temp/constants.hbar**2\n",
        "    forces = forces/np.sqrt(masses/1e3/constants.Avogadro)\n",
        "    forces = forces.reshape(t.n_frames,-1)*1e3/constants.Avogadro*1e9\n",
        "    sigma = LedoitWolf().fit(forces).covariance_\n",
        "    eigenvalues = linalg.eigvalsh(sigma)\n",
        "    kT_over_hbar_omega = constants.Boltzmann*temp*np.sqrt(prefactor/eigenvalues)\n",
        "    SPR = np.sum(np.log(kT_over_hbar_omega+1))/len(seq) # R\n",
        "\n",
        "    # calculate the center of mass\n",
        "    cm = np.sum(t.xyz*masses,axis=1)/masses.sum()\n",
        "    # calculate residue-cm distances\n",
        "    si = t.xyz - cm[:,np.newaxis,:]\n",
        "    q = np.einsum('jim,jin->jmn', si*masses,si)/masses.sum()\n",
        "    trace_q = np.trace(q,axis1=1,axis2=2)\n",
        "    # calculate rg\n",
        "    rgarray = np.sqrt(trace_q)\n",
        "    # calculate traceless matrix\n",
        "    mean_trace = np.trace(q,axis1=1,axis2=2)/3\n",
        "    q_hat = q - mean_trace.reshape(-1,1,1)*np.identity(3).reshape(-1,3,3)\n",
        "    # calculate asphericity\n",
        "    Delta_array = 3/2*np.trace(q_hat**2,axis1=1,axis2=2)/(trace_q**2)\n",
        "    # calculate oblateness\n",
        "    S_array = 27*linalg.det(q_hat)/(trace_q**3)\n",
        "    # calculate ensemble averages\n",
        "    block_tr_q_hat_2 = BlockAnalysis(np.trace(q_hat**2,axis1=1,axis2=2), multi=1)\n",
        "    block_tr_q_hat_2.SEM()\n",
        "    block_tr_q_2 = BlockAnalysis(trace_q**2, multi=1)\n",
        "    block_tr_q_2.SEM()\n",
        "    block_det_q_hat = BlockAnalysis(linalg.det(q_hat), multi=1)\n",
        "    block_det_q_hat.SEM()\n",
        "    block_tr_q_3 = BlockAnalysis(trace_q**3, multi=1)\n",
        "    block_tr_q_3.SEM()\n",
        "    Delta = 3/2*block_tr_q_hat_2.av/block_tr_q_2.av\n",
        "    S = 27*block_det_q_hat.av/block_tr_q_3.av\n",
        "    Delta_err = 3/2*error_ratio(block_tr_q_hat_2.av,block_tr_q_2.av,block_tr_q_hat_2.sem,block_tr_q_2.sem)\n",
        "    S_err = 27*error_ratio(block_det_q_hat.av,block_tr_q_3.av,block_det_q_hat.sem,block_tr_q_3.sem)\n",
        "    return rgarray, Delta_array, S_array, Delta, S, Delta_err, S_err, SPR\n",
        "\n",
        "def Rij(traj,w=None):\n",
        "    pairs = traj.top.select_pairs('all','all')\n",
        "    d = md.compute_distances(traj,pairs)\n",
        "    dmax = np.max(d)\n",
        "    nres = traj.n_atoms\n",
        "    ij = np.arange(2,nres,1)\n",
        "    diff = [x[1]-x[0] for x in pairs]\n",
        "    dij = np.empty(0)\n",
        "    for i in ij:\n",
        "        dij = np.append(dij,np.sqrt(np.average(np.mean(d[:,diff==i]**2,axis=1),weights=w,axis=0)))\n",
        "    f = lambda x,R0,v : R0*np.power(x,v)\n",
        "    popt, pcov = curve_fit(f,ij[ij>5],dij[ij>5],p0=[.4,.5])\n",
        "    nu = popt[1]\n",
        "    nu_err = pcov[1,1]**0.5\n",
        "    R0 = popt[0]\n",
        "    R0_err = pcov[0,0]**0.5\n",
        "    return ij,dij,dmax,nu,nu_err,R0,R0_err\n",
        "\n",
        "#energy functions\n",
        "HALR = lambda r,s,l : 4*0.8368*l*((s/r)**12-(s/r)**6)\n",
        "HASR = lambda r,s,l : 4*0.8368*((s/r)**12-(s/r)**6)+0.8368*(1-l)\n",
        "HA = lambda r,s,l : np.where(r<2**(1/6)*s, HASR(r,s,l), HALR(r,s,l))\n",
        "HASP = lambda r,s,l,rc : np.where(r<rc, HA(r,s,l)-HA(rc,s,l), 0)\n",
        "\n",
        "#force functions\n",
        "LJ_F = lambda r,s,rvec : -6*4*0.8368*(2*s**12/r**14-s**6/r**8)*rvec\n",
        "HA_F = lambda r,s,l,rvec : np.where(r<2**(1/6)*s, LJ_F(r,s,rvec), l*LJ_F(r,s,rvec))\n",
        "HASP_F = lambda r,s,l,rvec,rc : np.where(r<rc, HA_F(r,s,l,rvec), 0)\n",
        "\n",
        "DH_F = lambda r,yukawa_eps,yukawa_kappa,rvec : -yukawa_eps*np.exp(-r*yukawa_kappa)*(1+r*yukawa_kappa)/r**3*rvec\n",
        "DHSP_F = lambda r,yukawa_eps,yukawa_kappa,rvec,rc : np.where(r<rc, DH_F(r,yukawa_eps,yukawa_kappa,rvec), 0)\n",
        "\n",
        "def calc_energy_map(t,df,seq,rc,temp,ionic):\n",
        "    indices = t.top.select_pairs('all','all')\n",
        "    mask = np.abs(indices[:,0]-indices[:,1])>1 #exclude bonded pairs\n",
        "    indices = indices[mask]\n",
        "    dvec = md.compute_displacements(t,indices) #vector distances between pairs for each frame\n",
        "    d = linalg.norm(dvec,axis=2)\n",
        "    pairs = np.array(list(itertools.combinations(list(seq),2)))\n",
        "    pairs = pairs[mask]\n",
        "    sigmas = 0.5*(df.loc[pairs[:,0]].sigmas.values+df.loc[pairs[:,1]].sigmas.values)\n",
        "    lambdas = 0.5*(df.loc[pairs[:,0]].lambdas.values+df.loc[pairs[:,1]].lambdas.values)\n",
        "    RT = 8.3145*temp*1e-3\n",
        "    fepsw = lambda T : 5321/T+233.76-0.9297*T+0.1417*1e-2*T*T-0.8292*1e-6*T**3\n",
        "    epsw = fepsw(temp)\n",
        "    lB = 1.6021766**2/(4*np.pi*8.854188*epsw)*6.022*1000/RT\n",
        "    # Calculate the inverse of the Debye length\n",
        "    yukawa_kappa = np.sqrt(8*np.pi*lB*ionic*6.022/10)\n",
        "    qq = df.loc[pairs[:,0]].q.values*df.loc[pairs[:,1]].q.values\n",
        "    yukawa_eps = qq*lB*RT\n",
        "    emap = np.zeros(pairs.shape[0])\n",
        "    forces = np.zeros((t.n_frames,t.n_atoms,3))\n",
        "    dstd = np.std(d,axis=0)\n",
        "    for j,(r,rvec) in enumerate(zip(np.split(d,20,axis=0),np.split(dvec,20,axis=0))):\n",
        "        emap += np.nansum(HASP(r,sigmas[np.newaxis,:],lambdas[np.newaxis,:],rc),axis=0)\n",
        "        for i in range(t.n_atoms):\n",
        "            ndx_pairs = np.any(indices==i,axis=1)\n",
        "            forces[j*r.shape[0]:(j+1)*r.shape[0],i] = np.nansum(\n",
        "                HASP_F(r[:,ndx_pairs,np.newaxis],sigmas[np.newaxis,ndx_pairs,np.newaxis],\n",
        "                            lambdas[np.newaxis,ndx_pairs,np.newaxis],rvec[:,ndx_pairs],rc),axis=1)\n",
        "            forces[j*r.shape[0]:(j+1)*r.shape[0],i] += np.nansum(DHSP_F(r[:,ndx_pairs,np.newaxis],\n",
        "                            yukawa_eps[np.newaxis,ndx_pairs,np.newaxis],yukawa_kappa,rvec[:,ndx_pairs],4),axis=1)\n",
        "    return indices, emap/d.shape[0], forces, dstd\n",
        "\n",
        "def Ree(t):\n",
        "    return md.compute_distances( t, atom_pairs=np.array([[ 0,  len(list(t.top.atoms))-1]]) )[...,0]\n",
        "\n",
        "def maps(traj,residues,seq,temp,ionic):\n",
        "    #energy maps\n",
        "    df_emap = pd.DataFrame(index=range(traj.n_atoms),columns=range(traj.n_atoms),dtype=float)\n",
        "    df_dstd = pd.DataFrame(index=range(traj.n_atoms),columns=range(traj.n_atoms),dtype=float)\n",
        "    pairs, emap, forces, dstd = calc_energy_map(traj,residues,seq,2.0,temp,ionic)\n",
        "    for k,(i,j) in enumerate(pairs):\n",
        "        df_emap.loc[i,j] = emap[k]\n",
        "        df_emap.loc[j,i] = emap[k]\n",
        "        df_dstd.loc[i,j] = dstd[k]\n",
        "        df_dstd.loc[j,i] = dstd[k]\n",
        "    return df_emap, forces, df_dstd\n",
        "\n",
        "def kde(a, w=None, phi_eff=None, min_=None, max_=None):\n",
        "    if type(w) == 'NoneType':\n",
        "        w = np.full(len(a), 1)\n",
        "    if min_ == None:\n",
        "        min_ = np.min(a)\n",
        "    if max_ == None:\n",
        "        max_ = np.max(a)\n",
        "    x = np.linspace( min_, max_, num = 50 )\n",
        "    d = scs.gaussian_kde( a, bw_method = \"silverman\", weights = w ).evaluate(x)\n",
        "    u = DescrStatsW( a, weights = w )\n",
        "    n_eff = phi_eff*a.size if phi_eff!=None else a.size\n",
        "    return x,d/np.sum(d),u.mean,u.std/np.sqrt(n_eff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5916d21",
      "metadata": {
        "cellView": "form",
        "id": "c5916d21"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#FA003F'>BME Toolbox</font></b>\n",
        "def iBME(calc_file,exp_file,THETAS=np.array([1,10,20,50,75,100,200,400,750,1000,5000,10000])):\n",
        "    W = []\n",
        "    STATS = []\n",
        "\n",
        "    out = display(progress(0, THETAS.size), display_id=True)\n",
        "\n",
        "    for i,t in enumerate(THETAS):\n",
        "        print(f'Reweighting with theta={t:d}')\n",
        "        rew = BME.Reweight('ibme_t{}'.format(t))\n",
        "        rew.load(exp_file,calc_file)\n",
        "        rew.ibme(theta=t, iterations=25, ftol=0.001)\n",
        "\n",
        "        W.append(rew.get_ibme_weights()[-1])\n",
        "        STATS.append(rew.get_ibme_stats()[-1])\n",
        "        out.update(progress(i, THETAS.size))\n",
        "        #print('chi2={:.2f}, phi_eff={:.2f}'.format(STATS[-1][1],STATS[-1][2]))\n",
        "\n",
        "    return THETAS, np.array(STATS), np.array(W)\n",
        "\n",
        "def theta_loc(thetas, stats):\n",
        "    kneedle = KneeLocator(stats[...,2], stats[...,1], S=1, curve=\"convex\", direction=\"increasing\")\n",
        "    choice = np.array(thetas)[stats[...,2]==kneedle.knee][0]\n",
        "    return choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6276c1d",
      "metadata": {
        "cellView": "form",
        "id": "e6276c1d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title <b><font color='#45B69C'>1 - Run MD simulation</font></b>\n",
        "#@markdown The default option “AUTO” will set the simulation time depending on sequence length. The longer the IDR, the larger the ensemble of conformations it can adopt. Moreover, the reconfiguration time of IDRs increases with increasing sequence length. Therefore, longer sequences will require more sampling. Typical simulation times range from ca. 5 min (a 71-ns-long simulation of an IDR of 70 residues), 7 min (71-ns-long simulation of an IDR of 140 residues), to 34 min for a 373-ns-long simulation of an IDR of 351 residues.\n",
        "# Getting back variables from user inputs\n",
        "f = open('seq.fasta', 'r').readlines()\n",
        "NAME = f[0][1:].strip()\n",
        "SEQUENCE = f[1].strip()\n",
        "\n",
        "if os.path.exists('SAXS'):\n",
        "    EXPERIMENT = 'SAXS'\n",
        "else:\n",
        "    EXPERIMENT = None\n",
        "\n",
        "temperature, ionic_strength, pH = np.loadtxt('env_settings.txt', unpack=True)\n",
        "\n",
        "N_res = len(SEQUENCE)\n",
        "N_save = 7000 if N_res < 150 else int(np.ceil(3e-4*N_res**2)*1000)\n",
        "\n",
        "#@markdown Simulation time (ns):\n",
        "Simulation_time = \"AUTO\" #@param {type:\"raw\"}\n",
        "\n",
        "if Simulation_time == \"AUTO\":\n",
        "    N_res = len(SEQUENCE)\n",
        "    L = (N_res-1)*0.38+4\n",
        "    N_save = 7000 if N_res < 150 else int(np.ceil(3e-4*N_res**2)*1000)\n",
        "    nsteps = 1010*N_save\n",
        "    print('AUTO simulation length selected. Running for {} ns'.format(nsteps*0.01/1000))\n",
        "else:\n",
        "    nsteps = float(Simulation_time)*1000/0.01//N_save*N_save\n",
        "try:\n",
        "    shutil.rmtree(NAME)\n",
        "except:\n",
        "    pass\n",
        "simulate(residues,NAME,list(SEQUENCE),temp=temperature,ionic=ionic_strength,Hc=Hc,nsteps=nsteps,stride=N_save,eqsteps=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e69afe",
      "metadata": {
        "cellView": "form",
        "id": "62e69afe"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#45B69C'>2 - Simulation analysis</font></b>\n",
        "#@markdown This cell plots several conformational properties: radius of gyration, $R_g$; asphericity, $\\Delta$; prolateness, $S$; end-to-end distance, $R_{ee}$; and the apparent Flory scaling exponent, $\\nu$ (see https://doi.org/10.1038/s41586-023-07004-5). $\\nu$ is calculated from a nonlinear fit to the ensemble-averaged inter-residue distances, $\\sqrt{ \\langle R_{ij}^2 \\rangle }$, as a function of sequence separations, $|i-j|$.\n",
        "traj = md.load_xtc('{:s}/traj.xtc'.format(NAME), top='{:s}/top.pdb'.format(NAME))\n",
        "\n",
        "df_emap, forces, df_dstd = maps(traj,residues,SEQUENCE,temperature,ionic_strength)\n",
        "\n",
        "rg_array, D_array, S_array, D, S, D_err, S_err, SPR = calc_shape_and_entropy(traj,forces,\n",
        "                                                                    residues,SEQUENCE,temperature)\n",
        "\n",
        "rg, rg_err, rg_blocksize = autoblock(rg_array)\n",
        "x_rg, p_rg, _, _ = kde(rg_array)\n",
        "x_D, p_D, _, _ = kde(D_array)\n",
        "x_S, p_S, _, _ = kde(S_array)\n",
        "\n",
        "ree_array = Ree(traj)\n",
        "ree, ree_err, ree_blocksize = autoblock(ree_array)\n",
        "x_ree, p_ree, _, _ = kde(ree_array)\n",
        "\n",
        "ij,dij,dmax,nu,nu_err,R0,R0_err = Rij(traj)\n",
        "\n",
        "# Plot results\n",
        "mpl.rcParams.update({'font.size': 10})\n",
        "fig, axs = plt.subplots(2, 3, figsize=(7,3.5), facecolor='w', dpi=300, layout='tight')\n",
        "axs = axs.flatten()\n",
        "\n",
        "axs[0].plot(x_rg, p_rg)\n",
        "top = p_rg.max()+0.1*p_rg.max()\n",
        "axs[0].axvline(rg)\n",
        "# experimental Rg values from Guinier analysis performed with the ATSAS package (see SI of DOI: 10.1016/j.bpj.2022.12.013)\n",
        "exp_data = {'Hst5': {'exp_rg':1.34, 'exp_rg_err':0.05},\n",
        "            'RS': {'exp_rg':1.26, 'exp_rg_err':0.08},\n",
        "            'DSS1': {'exp_rg':2.5, 'exp_rg_err':0.1},\n",
        "            'Sic1': {'exp_rg':2.9, 'exp_rg_err':0.1},\n",
        "            'ProTa': {'exp_rg':3.7, 'exp_rg_err':0.2},\n",
        "            'NHE6cmdd': {'exp_rg':3.2, 'exp_rg_err':0.2},\n",
        "            'A1': {'exp_rg':2.5, 'exp_rg_err':0.1},\n",
        "            'aSyn': {'exp_rg':3.56, 'exp_rg_err':0.04},\n",
        "            'ANAC046': {'exp_rg':3.6, 'exp_rg_err':0.3},\n",
        "            'GHR-ICD': {'exp_rg':6.0, 'exp_rg_err':0.5},\n",
        "            'Tau': {'exp_rg':6.4, 'exp_rg_err':0.5}}\n",
        "\n",
        "if NAME in exp_data.keys():\n",
        "    axs[0].axvspan(exp_data[NAME]['exp_rg']-exp_data[NAME]['exp_rg_err'],\n",
        "               exp_data[NAME]['exp_rg']+exp_data[NAME]['exp_rg_err'], lw=0,\n",
        "               color='k',\n",
        "               alpha=.5)\n",
        "axs[0].axvspan(exp_data[NAME]['exp_rg']-exp_data[NAME]['exp_rg_err'],\n",
        "               exp_data[NAME]['exp_rg']+exp_data[NAME]['exp_rg_err'], lw=0,\n",
        "               color='k',\n",
        "               alpha=.5)\n",
        "axs[0].set_xlabel(r'$R_g$ (nm)')\n",
        "axs[0].set_ylabel(r'$p(R_g)$')\n",
        "axs[0].set_ylim(0,top)\n",
        "axs[0].fill_between([rg-rg_err,rg+rg_err],0,top,alpha=0.3)\n",
        "\n",
        "axs[1].plot(x_D, p_D)\n",
        "top = p_D.max()+0.1*p_D.max()\n",
        "axs[1].axvline(D)\n",
        "axs[1].set_xlabel(r'$\\Delta$')\n",
        "axs[1].set_ylabel(r'$p(\\Delta)$')\n",
        "axs[1].set_ylim(0,top)\n",
        "axs[1].fill_between([D-D_err,D+D_err],0,top,alpha=0.3)\n",
        "\n",
        "axs[2].plot(x_S, p_S)\n",
        "top = p_S.max()+0.1*p_S.max()\n",
        "axs[2].axvline(S)\n",
        "axs[2].set_xlabel(r'$S$')\n",
        "axs[2].set_ylabel(r'$p(S)$')\n",
        "axs[2].set_ylim(0,top)\n",
        "axs[2].fill_between([S-S_err,S+S_err],0,top,alpha=0.3)\n",
        "\n",
        "axs[3].plot(x_ree, p_ree)\n",
        "top = p_ree.max()+0.1*p_ree.max()\n",
        "axs[3].vlines(ree,0,top)\n",
        "axs[3].set_xlabel(r'$R_{ee}$ (nm)')\n",
        "axs[3].set_ylabel(r'$p(R_{ee})$')\n",
        "axs[3].set_ylim(0,top)\n",
        "\n",
        "axs[4].plot(ij,dij)\n",
        "dij_fit = R0*np.power(ij,nu)\n",
        "axs[4].plot(ij, dij_fit,c='0.3',ls='dashed',label='Fit')\n",
        "axs[4].set_xlabel('$|i-j|$')\n",
        "axs[4].set_ylabel(r'$\\sqrt{\\langle R_{ij}^2 \\rangle}$ (nm)')\n",
        "axs[4].text(0.05, 0.9, r'$\\nu$={:.2f}'.format(nu), horizontalalignment='left',\n",
        "            verticalalignment='center', transform=axs[4].transAxes, fontsize=10)\n",
        "axs[4].legend(loc='lower right')\n",
        "\n",
        "im = axs[5].imshow(df_emap*1e3,extent=[1, df_emap.shape[0], 1, df_emap.shape[0]],origin='lower',\n",
        "                   aspect='equal',vmin=-9,vmax=0,cmap=plt.cm.Blues_r)\n",
        "cb = plt.colorbar(im, ax=axs[5], label=r'$U$ (J mol$^{-1}$)',fraction=0.05, pad=0.04)\n",
        "cb.set_ticks([0,-3,-6,-9])\n",
        "axs[5].set_xlabel('Residue #')\n",
        "axs[5].set_ylabel('Residue #')\n",
        "\n",
        "plt.savefig(f'{NAME}/conformational_properties.pdf', dpi=300, facecolor='w', edgecolor='w', orientation='portrait',\n",
        "            bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "if NAME in exp_data.keys():\n",
        "    df_means = pd.DataFrame(data=np.c_[[exp_data[NAME]['exp_rg'],exp_data[NAME]['exp_rg_err']],\n",
        "                                   [rg,rg_err],[ree,ree_err],[nu,nu_err],[D,D_err],[S,S_err],[SPR,0]],\n",
        "                        columns=['Exp <Rg> (nm)','<Rg> (nm)','<Ree> (nm)','nu','<Delta>','<S>','S_conf/N (kB)'],\n",
        "                        index=['Value','Error'])\n",
        "else:\n",
        "    df_means = pd.DataFrame(data=np.c_[[rg,rg_err],[ree,ree_err],[nu,nu_err],[D,D_err],[S,S_err],[SPR,0]],\n",
        "                        columns=['<Rg> (nm)','<Ree> (nm)','nu','<Delta>','<S>','S_conf/N (kB)'],\n",
        "                        index=['Value','Error'])\n",
        "\n",
        "df_means.to_csv(f'{NAME}/conf_properties.csv')\n",
        "df_emap.to_csv(f'{NAME}/energy_map.csv')\n",
        "\n",
        "df_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217f213d",
      "metadata": {
        "cellView": "form",
        "id": "217f213d"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#F26419'>2.1 - Sequence analysis</font></b>\n",
        "#@markdown This cell calculates the following sequence descriptors: fractions of K, R, D, E, and aromatic residues; average stickiness, $\\langle \\lambda \\rangle$; sequence hydropathy decorator, SHD; sequence charge decorator, SCD; charge segregation parameter $\\kappa$; fraction of charged residues, FCR; and net charge per residue, NCPR. $\\langle \\lambda \\rangle$, SHD, SCD, $\\kappa$, and FCR will be used to estimate the apparent Flory scalingexponent, $\\nu_\\text{SVR}$, using a machine learning model trained on simulations of tens of thousands of sequences of human IDRs (see https://doi.org/10.1038/s41586-023-07004-5).\n",
        "df_seq = pd.DataFrame(columns=['fK','fR','fE','fD','fARO','mean_lambda','SHD','SCD','kappa',\n",
        "                           'FCR','NCPR','nu_SVR','S_conf,SVR/N (kB)'])\n",
        "f = open('seq.fasta', 'r').readlines()\n",
        "NAME = f[0][1:].strip()\n",
        "SEQUENCE = f[1].strip()\n",
        "temperature, ionic_strength, Hc = np.loadtxt('env_settings.txt', unpack=True)\n",
        "\n",
        "df_seq.loc[NAME] = calc_seq_prop(SEQUENCE,residues,Hc)\n",
        "\n",
        "df_seq.to_csv(f'{NAME}/sequence_properties.csv')\n",
        "\n",
        "df_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04387fa",
      "metadata": {
        "cellView": "form",
        "id": "b04387fa"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title <b><font color='#ffc413'>2.2 - Generate all-atom trajectory</font></b>\n",
        "THREE_LETTER_SEQ = [residues.three[x] for x in SEQUENCE]\n",
        "t_cg = fix_topology_pulchra(traj, THREE_LETTER_SEQ)\n",
        "\n",
        "#downsample the trajectory based on the size of blocks of correlated Rg and Ree values\n",
        "#n_skip = int((rg_blocksize+ree_blocksize)/2)\n",
        "\n",
        "#t_cg = t_cg[::n_skip]\n",
        "\n",
        "backmapping(NAME, t_cg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aeb4feb",
      "metadata": {
        "cellView": "form",
        "id": "2aeb4feb"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#058ED9'>3 - Ensemble reweighting against experimental data</b></font>\n",
        "#@markdown The Bayesian/Maximum-entropy approach is used to reweight the MD simulations so that it better matches the SAXS data. This is done by minimizing the functional, $L(w_1 ... w_n) = \\frac{m}{2}\\chi^2(w_1 ... w_n)-\\theta\\; S_{rel}(w_1 ... w_n)$, where $(w_1 ... w_n)$ are the statistical weights associated with each frame of the simulation, $\\chi^2$ quantifies the agreement between simulation and SAXS, $S_{rel}$ quantifies how much the new weights are different from the initial ones. $\\theta$ is a free parameter that must be tuned to strike a balance between obtaining a good agreement with the experimental data (low $\\chi^2$) and retaining as much information as possible from the starting simulation (high $S_{rel}$).\n",
        "#correct experimental errors with BIFT\n",
        "#f = open('inputfile.dat','w')\n",
        "#f.write(\"saxs_input.dat\\n\\n\\n\\n{}\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\".format(dmax))\n",
        "#f.close()\n",
        "#subprocess.run('./bift < inputfile.dat'.split())\n",
        "np.savetxt('{:s}_bift.dat'.format(NAME), np.loadtxt('saxs_input.dat'), header=' DATA=SAXS')\n",
        "#print('Experimental errors on SAXS intensities have been corrected with BIFT')\n",
        "#print('Factor used for rescaling errors is: {}'.format(np.loadtxt('scale_factor.dat')[0,1]))\n",
        "#print('SAXS data with corrected errors is in {:s}_bift.dat\\n'.format(NAME))\n",
        "\n",
        "#@markdown 1. We calculate SAXS curves for each trajectory frame using Pepsi-SAXS.\n",
        "#SAXS\n",
        "print('Calculating SAXS from all-atom trajectory...')\n",
        "t_aa = md.load_dcd('{}/traj_AA.dcd'.format(NAME), top='{}/top_AA.pdb'.format(NAME))\n",
        "for i,f in enumerate(t_aa):\n",
        "    f.save_pdb('frame.pdb')\n",
        "    pepsi_comm = './Pepsi-SAXS frame.pdb {:s}_bift.dat -o saxs.dat -cst --cstFactor 0 --I0 1.0 --dro 1.0 --r0_min_factor 1.025 --r0_max_factor 1.025 --r0_N 1'.format(NAME)\n",
        "    subprocess.run(pepsi_comm.split())\n",
        "    if i == 0:\n",
        "        calc_saxs = np.loadtxt('saxs.dat')[...,3]\n",
        "    else:\n",
        "        calc_saxs = np.vstack((calc_saxs,np.loadtxt('saxs.dat')[...,3]))\n",
        "col0 = np.arange(0,len(calc_saxs)).reshape(len(calc_saxs),1)\n",
        "calc_saxs = np.hstack((col0,calc_saxs))\n",
        "np.savetxt('calc_saxs.dat', calc_saxs)\n",
        "\n",
        "#@markdown 2. We execute BME reweighing using different $\\theta$ values. For each $\\theta$ value, we calculate $\\chi^2$ and $\\phi_{eff}=\\exp(S_{rel})$.\n",
        "def f(theta):\n",
        "    mpl.rcParams.update({'font.size': 10})\n",
        "    fig = plt.figure(layout='constrained',dpi=300,figsize=(7,3))\n",
        "    plt.scatter(stats[...,2],stats[...,1], c='k')\n",
        "    plt.scatter(stats[...,2][theta],stats[...,1][theta], c='tab:red',label=r'Chosen $\\theta$')\n",
        "    plt.xlabel(r'$\\phi_{eff}$',fontsize=10)\n",
        "    plt.ylabel(r'$\\chi^2_r$',fontsize=10)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return theta\n",
        "\n",
        "thetas, stats, weights = iBME('calc_saxs.dat', '{:s}_bift.dat'.format(NAME))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b><font color='#058ED9'>3.1 - Setting $\\theta$</b></font>\n",
        "#@markdown This cell plots $\\chi^2$ vs $\\phi_{eff}=\\exp(S_{rel})$ for the different $\\theta$ values scanned in the previous cell. The “THETA_LOCATOR” option identifies the optimal $\\theta$ value located at the elbow of the curve. Switching the “THETA_LOCATOR” option from “AUTO” to “INTERACTIVE”, you can use a drop-down menu to select a specific $\\theta$ value to use. After running cell 3.2 below, try selecting different $\\theta$ values, both high and low, and run cell 3.2 again. How do the structural observables and the fit to SAXS change in response to changes in $\\theta$?\n",
        "\n",
        "THETA_LOCATOR = \"AUTO\" #@param [\"AUTO\", \"INTERACTIVE\"]\n",
        "if THETA_LOCATOR == \"AUTO\":\n",
        "    choice = theta_loc(thetas, stats)\n",
        "    mpl.rcParams.update({'font.size': 10})\n",
        "    fig = plt.figure(layout='constrained',dpi=300,figsize=(7,3))\n",
        "    plt.scatter(stats[...,2],stats[...,1], c='k')\n",
        "    ndx = np.where(thetas==choice)[0][0]\n",
        "    plt.scatter(stats[...,2][ndx],stats[...,1][ndx], c='tab:red',label=r'Chosen $\\theta$')\n",
        "    plt.xlabel(r'$\\phi_{eff}$',fontsize=10)\n",
        "    plt.ylabel(r'$\\chi^2_r$',fontsize=10)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "elif THETA_LOCATOR == \"INTERACTIVE\":\n",
        "    interactive_plot = interactive(f, theta=list(zip(thetas,range(thetas.size))))\n",
        "    display(interactive_plot)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "o96AIo6tift7"
      },
      "id": "o96AIo6tift7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9acd4af",
      "metadata": {
        "cellView": "form",
        "id": "f9acd4af"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#058ED9'>3.2 Analyze reweighted ensemble</b></font>\n",
        "#@markdown This cell shows comparisons between SAXS curves and conformational properties from experiments (grey) and from the simulation trajectory before (blue) and after BME reweighting (red). As an exercise, go back to cell 1.1 and check the \"Break_CALVADOS\" box. That will add random noise up to 30% in CALVADOS' lambda values (the amino-acid stickiness parameters). As a consequence, the resulting force field will likely not reproduce the experimental data accurately and the effect of reweighting will be more evident.\n",
        "if THETA_LOCATOR == \"INTERACTIVE\":\n",
        "    ndx = interactive_plot.result\n",
        "    choice = thetas[ndx]\n",
        "\n",
        "print('Reweighting using theta={}'.format(choice))\n",
        "\n",
        "q, I_exp, err = np.loadtxt('{}_bift.dat'.format(NAME), unpack=True)\n",
        "I_prior = np.average(np.loadtxt('calc_saxs.dat')[...,1:],axis=0)\n",
        "I_post = np.average(np.loadtxt(list(filter(lambda x: x.startswith('ibme_t{}_'.format(choice)) and x.endswith('.calc.dat'), os.listdir('.')))[0])[...,1:], axis=0, weights=weights[ndx])\n",
        "wlr = 1/(err**2)\n",
        "model = LinearRegression()\n",
        "model.fit(I_prior.reshape(-1,1),I_exp,wlr)\n",
        "a = model.coef_[0]\n",
        "b = model.intercept_\n",
        "I_prior = a*I_prior+b\n",
        "\n",
        "mpl.rcParams.update({'font.size': 10})\n",
        "fig, axs = plt.subplots(3, 2, figsize=(7,6), facecolor='w', dpi=300, layout='constrained')\n",
        "axs = axs.flatten()\n",
        "\n",
        "axs[0].errorbar(q,I_exp,err,c='tab:gray',alpha=.5)\n",
        "axs[0].plot(q,I_prior, zorder=500)\n",
        "axs[0].plot(q,I_post, color='tab:red', zorder=1000)\n",
        "axs[0].set_xlabel(r'$q$ (nm$^{-1}$)')\n",
        "axs[0].set_ylabel('Intensity')\n",
        "axs[0].set_ylim(0,I_post.max()*1.1)\n",
        "axs[0].set_xlim(0,4)\n",
        "\n",
        "axs[1].errorbar(q,I_exp,err,lw=1,c='tab:gray',alpha=.5)\n",
        "axs[1].plot(q,I_prior, zorder=500)\n",
        "axs[1].plot(q,I_post, color='tab:red', zorder=1000)\n",
        "axs[1].set_xscale('log')\n",
        "axs[1].set_yscale('log')\n",
        "axs[1].set_xlabel(r'$q$ (nm$^{-1}$)')\n",
        "axs[1].set_ylabel('Intensity')\n",
        "axs[1].set_ylim(0,I_prior.max()*1.1)\n",
        "\n",
        "kratky_exp = (q**2)*I_exp\n",
        "kratky_err = (q**2)*err\n",
        "axs[2].errorbar(q,kratky_exp,kratky_err,c='tab:gray',alpha=.5)\n",
        "axs[2].plot(q,(q**2)*I_prior, zorder=500)\n",
        "axs[2].plot(q,(q**2)*I_post, color='tab:red', zorder=1000)\n",
        "axs[2].set_xlabel(r'$q$ (nm$^{-1}$)')\n",
        "axs[2].set_ylabel(r'$q^2I$')\n",
        "axs[2].set_ylim(0,((q**2)*I_post).max()*1.1)\n",
        "axs[2].set_xlim(0,4)\n",
        "\n",
        "axs[3].plot(q, (I_exp-I_prior)/err, color='tab:blue', lw=1)\n",
        "axs[3].plot(q, (I_exp-I_post)/err, color='tab:red', lw=1)\n",
        "axs[3].set_xlabel(r'$q$ (nm$^{-1}$)')\n",
        "axs[3].set_ylabel(r'$(I^\\mathrm{EXP}-I^\\mathrm{CALC})/\\sigma$')\n",
        "\n",
        "x_rg_rew, p_rg_rew, rg_av_rew, rg_se_rew = kde(rg_array, w=weights[ndx], phi_eff=stats[...,2][ndx], min_=np.min(rg_array), max_=np.max(rg_array))\n",
        "x_ree_rew, p_ree_rew, ree_av_rew, ree_se_rew = kde(ree_array, w=weights[ndx], phi_eff=stats[...,2][ndx], min_=np.min(ree_array), max_=np.max(ree_array))\n",
        "ij, dij_rew, dmax_rew, nu_rew, nu_err_rew, _, _ = Rij(traj, w=weights[ndx])\n",
        "\n",
        "plot_dist(axs[4], x_rg, p_rg, rg,color='tab:blue')\n",
        "plot_rew_dist(axs[4], x_rg_rew, p_rg_rew, rg_av_rew)\n",
        "\n",
        "if NAME in exp_data.keys():\n",
        "    axs[4].axvspan(exp_data[NAME]['exp_rg']-exp_data[NAME]['exp_rg_err'],\n",
        "               exp_data[NAME]['exp_rg']+exp_data[NAME]['exp_rg_err'], lw=0,\n",
        "               color='k',\n",
        "               alpha=.5)\n",
        "axs[4].set_xlabel(r'$R_g$ (nm)')\n",
        "axs[4].set_ylabel(r'$p(R_g)$')\n",
        "axs[4].annotate(xy=(0.95,0.85), xycoords='axes fraction', text=r'$\\langle R_g \\rangle={:.2f}$ nm'.format(rg_av_rew), color='tab:red', fontsize=10, horizontalalignment='right')\n",
        "\n",
        "axs[5].plot(ij,dij,c='tab:blue')\n",
        "axs[5].plot(ij,dij_rew,nu_rew,c='tab:red')\n",
        "axs[5].set_xlabel('$|i-j|$')\n",
        "axs[5].set_ylabel(r'$\\langle R_{ij} \\rangle$ (nm)')\n",
        "axs[5].annotate(xy=(0.05,0.85), xycoords='axes fraction', text=r'$\\nu$={:.2f}'.format(nu_rew), color='tab:red', fontsize=10)\n",
        "\n",
        "try:\n",
        "    os.mkdir(f'{NAME}/REWEIGHTED')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "plt.savefig(f'{NAME}/REWEIGHTED/SAXS_reweighting.pdf', dpi=300, facecolor='w', edgecolor='w', orientation='portrait',\n",
        "            bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff61c323",
      "metadata": {
        "cellView": "form",
        "id": "ff61c323"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#058ED9'>3.3 - Reweighted Conformational Properties</b></font>\n",
        "if NAME in exp_data.keys():\n",
        "    df_reweighted = pd.DataFrame(data=np.c_[[exp_data[NAME]['exp_rg'],exp_data[NAME]['exp_rg_err']],\n",
        "                                   [rg_av_rew,rg_se_rew],\n",
        "                                   [ree_av_rew,ree_se_rew],\n",
        "                                   [nu_rew,nu_err_rew]],\n",
        "                        columns=['Exp <Rg> (nm)','<Rg> (nm)','<Ree> (nm)','nu'],\n",
        "                        index=['Value','Error'])\n",
        "else:\n",
        "    df_reweighted = pd.DataFrame(data=np.c_[[rg_av_rew,rg_se_rew],\n",
        "                                   [ree_av_rew,ree_se_rew],\n",
        "                                   [nu_rew,nu_err_rew]],\n",
        "                        columns=['<Rg> (nm)','<Ree> (nm)','nu'],\n",
        "                        index=['Value','Error'])\n",
        "\n",
        "df_reweighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba880536",
      "metadata": {
        "cellView": "form",
        "id": "ba880536"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#058ED9'>3.4 - Conformational Properties Before Reweighting</b></font>\n",
        "if NAME in exp_data.keys():\n",
        "    df_not_reweighted = pd.DataFrame(data=np.c_[[exp_data[NAME]['exp_rg'],exp_data[NAME]['exp_rg_err']],\n",
        "                                   [rg,rg_err],[ree,ree_err],[nu,nu_err]],\n",
        "                        columns=['Exp <Rg> (nm)','<Rg> (nm)','<Ree> (nm)','nu'],\n",
        "                        index=['Value','Error'])\n",
        "else:\n",
        "    df_not_reweighted = pd.DataFrame(data=np.c_[[rg,rg_err],[ree,ree_err],[nu,nu_err]],\n",
        "                        columns=['<Rg> (nm)','<Ree> (nm)','nu'],\n",
        "                        index=['Value','Error'])\n",
        "df_not_reweighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13644949",
      "metadata": {
        "cellView": "form",
        "id": "13644949"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color='#72A276'>4 - Download results</b></font>\n",
        "#@markdown This cell triggers the download of a zip archive containing the data from the simulation and reweighting. The README file explains the content of the zip archive. The archive contains data that can be used to reproduce the plots from the notebook and the simulation files. The archive also contain trajectory and topology files that can be used to visualise the conformational ensemble using molecular visualisation software such as VMD, PyMol or Chimera.\n",
        "if Break_CALVADOS:\n",
        "    folder_name = f'{NAME}_Broken_EnsembleLab'\n",
        "else:\n",
        "    folder_name = f'{NAME}_EnsembleLab'\n",
        "\n",
        "try:\n",
        "    os.remove(f'{NAME}/pretraj.dcd')\n",
        "    os.remove(f'{NAME}/restart.chk')\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    shutil.move('seq.fasta',f'{NAME}/seq.fasta','w')\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    shutil.move('env_settings.txt',f'{NAME}/env_settings.txt','w')\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    os.mkdir(folder_name)\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    shutil.copytree(f'{NAME}/REWEIGHTED',f'{folder_name}/REWEIGHTED')\n",
        "    shutil.rmtree(f'{NAME}/REWEIGHTED')\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    shutil.copytree(f'{NAME}',f'{folder_name}/SIMULATION')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "pd.DataFrame(data=np.c_[rg_array,ree_array,D_array,S_array,weights[ndx]],\n",
        "             columns=['Rg (nm)','Ree (nm)','Delta','S','weights']).to_csv(\n",
        "             f'{NAME}/time_series_Rg_Ree_Delta_S.csv'.format(NAME))\n",
        "pd.DataFrame(data=np.c_[ij,dij],\n",
        "             columns=['ij','Rij (nm)']).to_csv(f'{NAME}/scaling_profile.csv')\n",
        "pd.DataFrame(data=np.c_[ij,dij_rew],\n",
        "             columns=['ij','Reweighted Rij (nm)']).to_csv(f'{folder_name}/REWEIGHTED/reweighted_scaling_profile.csv')\n",
        "\n",
        "df_means.to_csv(f'{folder_name}/REWEIGHTED/reweighted_conf_properties.csv')\n",
        "\n",
        "np.savetxt(f'{folder_name}/REWEIGHTED/saxs.dat', np.vstack((q,I_exp,err,I_prior,I_post)).T, header='q I(exp) err(bift) I(prior) I(post)')\n",
        "wget.download('https://raw.githubusercontent.com/gitesei/EnsembleLab/main/utils/readme_download_simulation.txt')\n",
        "fout = open(f'{folder_name}/README', 'w')\n",
        "fout.write(''.join(open('readme_download_simulation.txt', 'r').readlines()))\n",
        "fout.write('\\n')\n",
        "wget.download('https://raw.githubusercontent.com/gitesei/EnsembleLab/main/utils/readme_download_reweighted.txt')\n",
        "fout.write(''.join(open('readme_download_reweighted.txt', 'r').readlines()))\n",
        "fout.close()\n",
        "\n",
        "zipper = f'zip -r {folder_name}.zip {folder_name}'\n",
        "\n",
        "subprocess.run(zipper.split())\n",
        "\n",
        "files.download(f'{folder_name}.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}